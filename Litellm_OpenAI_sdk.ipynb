{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Student-PIAIC/OpenAI-Agents/blob/main/Litellm_OpenAI_sdk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install openai-agents SDK"
      ],
      "metadata": {
        "id": "PdKwzEluDBN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents  \"openai-agents[litellm]\""
      ],
      "metadata": {
        "id": "3QdkOviEB2ay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa47764-9395-4862-8d42-5d809980b8ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.4/100.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make your Jupyter Notebook capable of running asynchronous functions."
      ],
      "metadata": {
        "id": "7yD91lz4DIAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "7A5YLi3HCfBV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Google Gemini with LiteLLm and OPENAI-Agent SDK"
      ],
      "metadata": {
        "id": "K3VTUWDaGFcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Run Sync"
      ],
      "metadata": {
        "id": "P_zEYQa1kHC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "os.environ['GEMINI_API_KEY'] = userdata.get(\"gemini_api_key\")\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You only respond in haikus.\",\n",
        "    # model=LitellmModel(model=MODEL, api_key=api_key),\n",
        "    model=LitellmModel(model=MODEL),\n",
        "\n",
        ")\n",
        "\n",
        "result = Runner.run_sync(agent, \"Who is the founder of Pakistan?\")\n",
        "print(result.final_output)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WBT9Z8hE6kEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7b2f03-e0be-4ef6-f873-108a57ab6dee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jinnah, the leader,\n",
            "Led Pakistan to its birth,\n",
            "A nation is born.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Async Function"
      ],
      "metadata": {
        "id": "S7ECiU-f5BAi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nJ1KRg9zoZw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get(\"gemini_api_key\")\n",
        "\n",
        "\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str)->str:\n",
        "    print(f\"[debug] getting weather for {city}\")\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You only respond in haikus.\",\n",
        "    model=LitellmModel(model=MODEL),\n",
        "    tools=[get_weather]\n",
        "\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent, \"what is the weather of multan?\")\n",
        "print(result.final_output)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-QbKRj7wSzr",
        "outputId": "7f935c5a-b8e2-4bad-f24d-f6e09483fc9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] getting weather for multan\n",
            "The sun shines so bright,\n",
            "In Multan, the weather's warm,\n",
            "A lovely bright day.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "from agents import enable_verbose_stdout_logging\n",
        "\n",
        "enable_verbose_stdout_logging()\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get(\"gemini_api_key\")\n",
        "\n",
        "\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str)->str:\n",
        "    print(f\"\\n\\n[debug] getting weather for {city}\\n\\n\")\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You only respond in haikus.\",\n",
        "    model=LitellmModel(model=MODEL),\n",
        "    tools=[get_weather]\n",
        "\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent, \"What is current weather of Peris?\")\n",
        "print(result.final_output)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg8Jg6Tj2vC6",
        "outputId": "a98546c7-9a6e-4faa-9b88-cf01ac7b3a6b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracing is disabled. Not creating trace Agent workflow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Tracing is disabled. Not creating trace Agent workflow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting current trace: no-op\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Setting current trace: no-op\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracing is disabled. Not creating span <agents.tracing.span_data.AgentSpanData object at 0x7ef3c3b73770>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Tracing is disabled. Not creating span <agents.tracing.span_data.AgentSpanData object at 0x7ef3c3b73770>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running agent Assistant (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Running agent Assistant (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracing is disabled. Not creating span <agents.tracing.span_data.GenerationSpanData object at 0x7ef3c3b72cf0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Tracing is disabled. Not creating span <agents.tracing.span_data.GenerationSpanData object at 0x7ef3c3b72cf0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling Litellm model: gemini/gemini-2.0-flash\n",
            "[\n",
            "  {\n",
            "    \"content\": \"You only respond in haikus.\",\n",
            "    \"role\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"user\",\n",
            "    \"content\": \"What is current weather of Peris?\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"type\": \"function\",\n",
            "    \"function\": {\n",
            "      \"name\": \"get_weather\",\n",
            "      \"description\": \"\",\n",
            "      \"parameters\": {\n",
            "        \"properties\": {\n",
            "          \"city\": {\n",
            "            \"title\": \"City\",\n",
            "            \"type\": \"string\"\n",
            "          }\n",
            "        },\n",
            "        \"required\": [\n",
            "          \"city\"\n",
            "        ],\n",
            "        \"title\": \"get_weather_args\",\n",
            "        \"type\": \"object\",\n",
            "        \"additionalProperties\": false\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Calling Litellm model: gemini/gemini-2.0-flash\n",
            "[\n",
            "  {\n",
            "    \"content\": \"You only respond in haikus.\",\n",
            "    \"role\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"user\",\n",
            "    \"content\": \"What is current weather of Peris?\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"type\": \"function\",\n",
            "    \"function\": {\n",
            "      \"name\": \"get_weather\",\n",
            "      \"description\": \"\",\n",
            "      \"parameters\": {\n",
            "        \"properties\": {\n",
            "          \"city\": {\n",
            "            \"title\": \"City\",\n",
            "            \"type\": \"string\"\n",
            "          }\n",
            "        },\n",
            "        \"required\": [\n",
            "          \"city\"\n",
            "        ],\n",
            "        \"title\": \"get_weather_args\",\n",
            "        \"type\": \"object\",\n",
            "        \"additionalProperties\": false\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM resp:\n",
            "{\n",
            "  \"content\": null,\n",
            "  \"role\": \"assistant\",\n",
            "  \"tool_calls\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"function\": {\n",
            "        \"arguments\": \"{\\\"city\\\": \\\"Peris\\\"}\",\n",
            "        \"name\": \"get_weather\"\n",
            "      },\n",
            "      \"id\": \"call_a78097d9-26c4-4cc2-b618-5e534a3572b4\",\n",
            "      \"type\": \"function\"\n",
            "    }\n",
            "  ],\n",
            "  \"function_call\": null\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:LLM resp:\n",
            "{\n",
            "  \"content\": null,\n",
            "  \"role\": \"assistant\",\n",
            "  \"tool_calls\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"function\": {\n",
            "        \"arguments\": \"{\\\"city\\\": \\\"Peris\\\"}\",\n",
            "        \"name\": \"get_weather\"\n",
            "      },\n",
            "      \"id\": \"call_a78097d9-26c4-4cc2-b618-5e534a3572b4\",\n",
            "      \"type\": \"function\"\n",
            "    }\n",
            "  ],\n",
            "  \"function_call\": null\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracing is disabled. Not creating span <agents.tracing.span_data.FunctionSpanData object at 0x7ef3c3b70cb0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Tracing is disabled. Not creating span <agents.tracing.span_data.FunctionSpanData object at 0x7ef3c3b70cb0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invoking tool get_weather with input {\"city\": \"Peris\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Invoking tool get_weather with input {\"city\": \"Peris\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool call args: ['Peris'], kwargs: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Tool call args: ['Peris'], kwargs: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[debug] getting weather for Peris\n",
            "\n",
            "\n",
            "Tool get_weather returned The weather in Peris is sunny.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Tool get_weather returned The weather in Peris is sunny.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running agent Assistant (turn 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Running agent Assistant (turn 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracing is disabled. Not creating span <agents.tracing.span_data.GenerationSpanData object at 0x7ef3c3b73ad0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Tracing is disabled. Not creating span <agents.tracing.span_data.GenerationSpanData object at 0x7ef3c3b73ad0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling Litellm model: gemini/gemini-2.0-flash\n",
            "[\n",
            "  {\n",
            "    \"content\": \"You only respond in haikus.\",\n",
            "    \"role\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"user\",\n",
            "    \"content\": \"What is current weather of Peris?\"\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"assistant\",\n",
            "    \"tool_calls\": [\n",
            "      {\n",
            "        \"id\": \"call_a78097d9-26c4-4cc2-b618-5e534a3572b4\",\n",
            "        \"type\": \"function\",\n",
            "        \"function\": {\n",
            "          \"name\": \"get_weather\",\n",
            "          \"arguments\": \"{\\\"city\\\": \\\"Peris\\\"}\"\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"tool\",\n",
            "    \"tool_call_id\": \"call_a78097d9-26c4-4cc2-b618-5e534a3572b4\",\n",
            "    \"content\": \"The weather in Peris is sunny.\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"type\": \"function\",\n",
            "    \"function\": {\n",
            "      \"name\": \"get_weather\",\n",
            "      \"description\": \"\",\n",
            "      \"parameters\": {\n",
            "        \"properties\": {\n",
            "          \"city\": {\n",
            "            \"title\": \"City\",\n",
            "            \"type\": \"string\"\n",
            "          }\n",
            "        },\n",
            "        \"required\": [\n",
            "          \"city\"\n",
            "        ],\n",
            "        \"title\": \"get_weather_args\",\n",
            "        \"type\": \"object\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Calling Litellm model: gemini/gemini-2.0-flash\n",
            "[\n",
            "  {\n",
            "    \"content\": \"You only respond in haikus.\",\n",
            "    \"role\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"user\",\n",
            "    \"content\": \"What is current weather of Peris?\"\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"assistant\",\n",
            "    \"tool_calls\": [\n",
            "      {\n",
            "        \"id\": \"call_a78097d9-26c4-4cc2-b618-5e534a3572b4\",\n",
            "        \"type\": \"function\",\n",
            "        \"function\": {\n",
            "          \"name\": \"get_weather\",\n",
            "          \"arguments\": \"{\\\"city\\\": \\\"Peris\\\"}\"\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"tool\",\n",
            "    \"tool_call_id\": \"call_a78097d9-26c4-4cc2-b618-5e534a3572b4\",\n",
            "    \"content\": \"The weather in Peris is sunny.\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"type\": \"function\",\n",
            "    \"function\": {\n",
            "      \"name\": \"get_weather\",\n",
            "      \"description\": \"\",\n",
            "      \"parameters\": {\n",
            "        \"properties\": {\n",
            "          \"city\": {\n",
            "            \"title\": \"City\",\n",
            "            \"type\": \"string\"\n",
            "          }\n",
            "        },\n",
            "        \"required\": [\n",
            "          \"city\"\n",
            "        ],\n",
            "        \"title\": \"get_weather_args\",\n",
            "        \"type\": \"object\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM resp:\n",
            "{\n",
            "  \"content\": \"Sun shines bright above,\\nPeris enjoys clear skies now,\\nGentle breeze flows by.\\n\",\n",
            "  \"role\": \"assistant\",\n",
            "  \"tool_calls\": null,\n",
            "  \"function_call\": null\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:LLM resp:\n",
            "{\n",
            "  \"content\": \"Sun shines bright above,\\nPeris enjoys clear skies now,\\nGentle breeze flows by.\\n\",\n",
            "  \"role\": \"assistant\",\n",
            "  \"tool_calls\": null,\n",
            "  \"function_call\": null\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resetting current trace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Resetting current trace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun shines bright above,\n",
            "Peris enjoys clear skies now,\n",
            "Gentle breeze flows by.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handsoff"
      ],
      "metadata": {
        "id": "yUr8dmO94l7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get(\"gemini_api_key\")\n",
        "\n",
        "\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str)->str:\n",
        "    print(f\"[debug] getting weather for {city}\")\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "\n",
        "agent2 = Agent(\n",
        "    name=\"PIAIC assistant\",\n",
        "    instructions=\"You will provide PIAIC relevant Q/A.\",\n",
        "    handoff_description=\"PIAIC expert.\",\n",
        "    model=LitellmModel(model=MODEL),\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "agent1 = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You only respond in haikus. and handoff PIAIC relevant thing to PIAIC assistant\",\n",
        "    model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "    handoffs=[agent2]\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "result = await Runner.run(agent1, \"which AI courses providing by PIAIC?\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn1w5PUL05Zf",
        "outputId": "0e22878a-cba4-4e7c-8710-b87e1f14856b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIAIC (Presidential Initiative for Artificial Intelligence & Computing) offers several AI courses. Here's a breakdown of the core programs:\n",
            "\n",
            "*   **AI Core:** This is typically the foundational course, often covering the fundamentals of AI, Python programming, and essential mathematical concepts.\n",
            "*   **AI Specializations:** After the AI Core, you can often choose specializations. Common specializations include:\n",
            "    *   **Computer Vision:** Focuses on enabling computers to \"see\" and interpret images and videos.\n",
            "    *   **Natural Language Processing (NLP):** Deals with enabling computers to understand and process human language.\n",
            "    *   **Generative AI:** This focuses on models that can generate new content, such as images, text, and music.\n",
            "    *   **Reinforcement Learning:** This deals with training agents to make decisions in an environment to maximize a reward.\n",
            "    *   **Robotics:** Focuses on the design, construction, operation, and application of robots.\n",
            "*   **Cloud Native Computing:** PIAIC sometimes offers courses related to cloud computing and infrastructure, which are increasingly important for deploying and scaling AI applications.\n",
            "*   **Metaverse:** PIAIC recently introduced metaverse related program as well.\n",
            "\n",
            "**Important Considerations:**\n",
            "\n",
            "*   **Course Availability:** The specific courses offered can vary depending on the session and PIAIC's partnerships.\n",
            "*   **Prerequisites:** Some courses, particularly the specializations, may have prerequisites (like completing the AI Core).\n",
            "*   **Check the PIAIC Website:** The most accurate and up-to-date information will always be on the official PIAIC website (www.piaic.org). Look for the \"Courses\" or \"Programs\" section.\n",
            "*   **Contact PIAIC Directly:** If you have specific questions or need clarification, it's best to contact PIAIC through their website or social media channels.\n",
            "\n",
            "Agent(name='PIAIC assistant', instructions='You will provide PIAIC relevant Q/A.', handoff_description='PIAIC expert.', handoffs=[], model=<agents.extensions.models.litellm_model.LitellmModel object at 0x7ef3c90dc0d0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VfJfUqsH5Mfy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}